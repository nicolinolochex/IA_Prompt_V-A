# Evaluador Automatizado de Empresas SegÃºn Requerimientos (E3)

## ğŸŒ Accede a la AplicaciÃ³n Web ğŸ“Œ

La aplicaciÃ³n ya estÃ¡ desplegada y lista para su uso en:

ğŸ”— **[Company Research Tool](https://iapromptv-a-2eqe8j67tnkvat972ihnmy.streamlit.app/)**

---

## ğŸ“Œ Resumen del Proyecto

Este sistema automatiza la investigaciÃ³n de empresas a partir de informaciÃ³n disponible en la web, con el objetivo de facilitar el trabajo del equipo de **Adquisiciones**. Basado en parÃ¡metros definidos como:

- **Headcount** (NÃºmero de empleados)
- **Servicios ofrecidos**
- **Revenue** (Ingresos anuales)
- **UbicaciÃ³n del Headquarter**
- **Descripcion de la empresa**


---

## ğŸš€ Funcionalidades Clave

### âœ… 1. ExtracciÃ³n de InformaciÃ³n desde Sitios Web y Perfiles de LinkedIn

- **Objetivo:** Recopilar y procesar informaciÃ³n clave de empresas desde sus sitios web y/o perfiles de LinkedIn.
- **ImplementaciÃ³n:**
  - Uso de **web scraping** con `BeautifulSoup` para obtener contenido relevante.
  - Procesamiento con **GPT-4** para extraer y estructurar la informaciÃ³n.
  - GeneraciÃ³n de un resumen claro y conciso con datos clave.

ğŸ”¹ **Ejemplo de Prompt:**

> "Dado el contenido web extraÃ­do, genera un JSON con los siguientes datos: nombre, website, tipo de empresa (pÃºblica, privada, adquirida, etc.), paÃ­s, breve descripciÃ³n, servicios, headcount y revenue."



### âœ… 2. GeneraciÃ³n de Reportes y ExportaciÃ³n de Datos

- **Objetivo:** Facilitar la visualizaciÃ³n y descarga de la informaciÃ³n extraÃ­da.
- **ImplementaciÃ³n:**
  - PresentaciÃ³n en formato de tabla dentro de la app.
  - **ExportaciÃ³n a CSV** para anÃ¡lisis externo.
  - **BotÃ³n de descarga** para obtener los datos estructurados.

ğŸ”¹ **Ejemplo:**

> GeneraciÃ³n de un archivo `companies_info.csv` con la informaciÃ³n procesada.

---

## ğŸ—ï¸ Arquitectura de la AplicaciÃ³n

La aplicaciÃ³n estÃ¡ desarrollada utilizando:

- **Streamlit**: Para la interfaz web.
- **Python**: Para la lÃ³gica del backend.
- **BeautifulSoup**: Para el scraping de datos.
- **OpenAI API (GPT-4)**: Para la extracciÃ³n y anÃ¡lisis de datos.
- **Pandas**: Para estructurar los datos y generar reportes en CSV.
- **Dotenv**: Para la gestiÃ³n segura de la API Key de OpenAI.

### ğŸ“‚ Estructura del Proyecto

```
ğŸ“‚ Proyecto E3
â”‚â”€â”€ .env              # Archivo con API Key (no se sube al repo)
â”‚â”€â”€ .gitignore        # Ignora archivos sensibles
â”‚â”€â”€ app.py            # CÃ³digo principal de la app
â”‚â”€â”€ README.md         # DocumentaciÃ³n del proyecto
â”‚â”€â”€ requeriments.txt  # Dependencias del proyecto
â””â”€â”€â”€ .devcontainer    # ConfiguraciÃ³n para entornos de desarrollo
```

---

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

Para ejecutar el proyecto en local:

1. **Clonar el repositorio:**

   ```bash
   git clone https://github.com/tu-repositorio/aqui.git
   cd proyecto-e3
   ```

2. **Instalar dependencias:**

   ```bash
   pip install -r requeriments.txt
   ```

3. **Configurar la API Key de OpenAI:**

   - Crear un archivo `.env` con el siguiente contenido:
     ```plaintext
     OPENAI_API_KEY=tu_api_key_aqui
     ```

4. **Ejecutar la aplicaciÃ³n:**

   ```bash
   streamlit run app.py
   ```

---

## ğŸŒŸ PrÃ³ximos Pasos

âœ”ï¸ **Mejorar la extracciÃ³n de datos** para reducir errores en LinkedIn.
âœ”ï¸ **Crear un monitor de usuarios
âœ”ï¸ **Agregar mÃ¡s criterios de selecciÃ³n** segÃºn necesidades del equipo.
âœ”ï¸ **Implementar una base de datos** para almacenar bÃºsquedas pasadas.
âœ”ï¸ **Implementar una base de datos** para almacenar bÃºsquedas pasadas.
âœ”ï¸ **Mejorar el input de webs
âœ”ï¸ **Mejorar la seguridad en general




